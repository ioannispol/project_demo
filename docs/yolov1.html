---

title: YOLO V1 implementation


keywords: fastai
sidebar: home_sidebar

summary: "YOLO v1."
description: "YOLO v1."
nb_path: "00_yolov1.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_yolov1.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Change to yolo dir: /media/ioannis/DATA/Documents/Machine_learning/Project/src/yolo_v1
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this notebook the YOLOv1 will implemented based on the original <a href="https://arxiv.org/pdf/1506.02640v5.pdf">paper</a></p>
<p>TODO:</p>
<ul>
<li>[ ] Need to rewrite the plot function so to give the name and the probability prediction for each bounding box</li>
<li>[ ] Get more metrics from the training function (e.g. training and validation losses)</li>
<li>[ ] Write a function that will plot the training and validation loss as well as the training and validation accuracy</li>
<li>[ ] Use the model on the videos that I have from towing tank to see how well the algorithm performs</li>
<li>[ ] Use images/videos with darker light conditions to train and test the model.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="How-Yolo-works">How Yolo works<a class="anchor-link" href="#How-Yolo-works"> </a></h1><p>Yolo is an object detection algorithm and uses features that learned from a cnn network to detect objects. When prerforming object detection we want to correctly identify in the image the objects in the given image. Most of the classic aproaches in the object detection algorithms using the sliding window method where the classifier is run over evenly spaces lacations over the entire image. Such types of algorithms are the Deformable Parts Models (DPM), the R-CNN which uses proposal methods to generate the bounding boxes in the given image and then run the classifier on the proposed bounding boxes. This approch, and particullarly the DPM method is slow and not optimal for real time uses, and the improved version of R-CNN models is gaining some speed by strategically selecting interesting regions and run through them the classifier.</p>
<p>On the other hand YOLO algorithm based on the idea to split the image in a grid, for axample for a given image we can split it in a 3 by 3 grid (<strong><em>SxS = 3x3</em></strong>) which gives as 9 cells. As the below image shows, the image consists by a 3 by 3 grid with 9 cells, and each cell has 2 bouning boxes (<strong><em>B</em></strong>) which finally will give the prediction bounding boxe for the object in the image.</p>
<p>{% include image.html alt="Bounding Boxes" width="500" caption="Bounding Boxes" id="bboxs" max-width="500" file="/proejct_demo/images/image.png" %}</p>
<p>Figure 1</p>
<p>Generally, the YOLO algorithm has the following steps:</p>
<ol>
<li>Divide the image into cells with an <strong><em>SxS</em></strong> grid</li>
<li>Each cell predicts <strong><em>B</em></strong> bounding boxes (<em>A cell is responsible for detecting an object if the object's bounding box is within the cell</em></li>
<li>Return bounding boxes above a given confidence threshold. <em>The algorithm will show only the bounding box with the highest probability confidence (e.g. 0.90) and will reject all boxes with less values than this threshold</em>.</li>
</ol>
<p><strong>Note:</strong> In practice will like touse larger values of $S and B$, such as $S = 19$ and $B = 5$ to identify more objects, and each cell will output a prediction with a corresponding bounding box for a given image.</p>
<p>The below image shows the YOLO algorithm's result, which returns the bounding boxes for the detected objects. For the algorithm to perform efficiently needs to be trained sufficiently because with each iteration (epoch), the detection accuracy increases. Also, the bounding boxes can be in more than one cells without any issue, and the detection is performed in the cell where the midpoint of the bounding box belongs.</p>
<p>{% include image.html alt="Bounding Boxes2" width="500" caption="Bounding Boxes2" id="bboxs2" max-width="500" file="/proejct_demo/images/image2.png" %}</p>
<p>Figure 2</p>
<p>The YOLO object detection algorithm is faster architecture because uses one Convolutional Neural Network (CNN) to run all components in the given image in contrast with the naive sliding window approach where for each image the algorithm (DPM, R-CNN etc) needs to scan it step by step to find the region of interest, the detected objects. The R-CNN for example needs classify around 2000 regions per image which makes the algorithm very time consuming and it's not ideal for real time applications.</p>
<p>The figure below shows how the YOLO model creates an $S x S$ grid in the input image and then for each grid cell creates multiple bounding boxes as well as class probability map, and at the end gives the final predictions of the objects in the image.</p>
<p>{% include image.html alt="Bounding Boxesy" width="500" caption="Bounding Boxesy" id="bboxs" max-width="500" file="/proejct_demo/images/yolo_paper.png" %}</p>
<p>Figure 3</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-the-bouning-boxes-are-encoded-in-YOLO?">How the bouning boxes are encoded in YOLO?<a class="anchor-link" href="#How-the-bouning-boxes-are-encoded-in-YOLO?"> </a></h2><p>One of the most important aspects of this algorithm is the it builds and specifies the bounding boxes, and the other is the the Loss function. The algorithm uses five components to predict an output:</p>
<ol>
<li>The centre of a bounding box $(b_x b_y)$ relative to the bounds of the grid cell</li>
<li>The width $(b_w)$</li>
<li>The height $(b_h)$. The width and the height of the entire image.</li>
<li>The class of the object $(c)$</li>
<li>The prediction confidence $(p_c)$ which is the probability of the existance of an object within the bounding box.</li>
</ol>
<p>Thus, we, optimally, want one bounding box for each object in the given image and we can be sure that only one object will be predicted for each object by taking the midpoint of the cell that is responsible for outputing that object.</p>
<p>So, each bounding box for each cell will have $[x_1, y_1, x_2, y_2]$ coordinates where in the YOLO algorithm will be $[x, y, w, h]$</p>
<ul>
<li>$x$ and $y$ will be the coordinates for object midpoint in cell -&gt; these actually will be between $0 - 1$</li>
<li>$w$ and $h$ will be the width and the heigth of that object relative to the cell -&gt; $w$ can be <em>greater</em> than 1, if the object is wider than the cell, and $h$ can also be <em>greater</em> than 1, if the object is taller than the cell</li>
</ul>
<p>The labels will look like the following:</p>
<p>$label_{cell} = [c_1, c_2, ..., c_5, p_c, x, y, w,h]$</p>
<p>where:</p>
<ul>
<li>$c_1$ to $c_5$ will be the dataset classes</li>
<li>$p_c$ probability that there is an object (1 or 0)</li>
<li>$x, y, w,h$ are the coordinates of the bounding boxes</li>
</ul>
<p>Predictions will look very similar, but will output two bouning boxes (will specialise to output different bounfding boxes (wide vs tall).</p>
<p>$pred_{cell} = [c_1, c_2, ..., c_5, p_{c_1}, x_1, y_1, w_1, h_1, p_{c_2}, x_2, y_2, w_2, h_2]$</p>
<p><strong>Note:</strong> A cell can only detect one object, this is also one of the YOLO limitations (we can have finer grid to achieve multiple detections as mentioned above.</p>
<p>This is for every cell and the <strong>target</strong> shape for one image will be $(S, S, 10)$</p>
<p>where:</p>
<ul>
<li>$S * S$ is the grid size</li>
<li>$5$ is for the class predictions, $1$ is for the probability score, and $4$ is for the bouning boxes</li>
</ul>
<p>The <strong>predictions</strong> shape will be $(S, S, 15)$ where there is and additional probability score and four extra bounding box predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-model-architecture">The model architecture<a class="anchor-link" href="#The-model-architecture"> </a></h2><p>{% include image.html alt="YOLO Architecture" width="800" caption="YOLO Architecture" id="yolov1" max-width="800" file="/proejct_demo/images/model.png" %}</p>
<p>The original YOLO model consists of 24 convolutional layers followed by 2 fully connected layers.
The model accepts 448x448 images and at the first layer has a 7x7 kernel with 64 output filters with stride of 2 (<strong>also need to have a padding of 3 to much the dimensions</strong>), also there is a 2x2 Maxpool Layer with the stride of 2. Simillarly, the rest of the model consists of convolutional layers and Maxpool layers except the last two layers where there are a fully conected layers where the first one takes as and input the convolutional output and make it a linear layer of 4096 feature vector and outputs to the fully connected which is reshaped to become a 7 by 7 by 30 which is the final split size of the image ($S = 7$ which is a $7$ x $7$ grid) with a vector output of 30 (in my case this will be 15).</p>
<p>To help whith the architecture building it will be usefull to pre-determine the architecure configuration:</p>
<div class="highlight"><pre><span></span><span class="n">architecture_config</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># Tuple: (kernel_size, num_filters, stride, padding)</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
    <span class="s2">&quot;M&quot;</span><span class="p">,</span>    <span class="c1"># M stands for the MaxPolling Layer and has stride 2x2 and kernel 2x2</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;M&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="s2">&quot;M&quot;</span><span class="p">,</span>
    <span class="c1"># List of tuples: (kernel_size, num_filters, stride, padding), num_of_repeats</span>
    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;M&quot;</span><span class="p">,</span> 
    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">],</span> 
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Loss-Function">The Loss Function<a class="anchor-link" href="#The-Loss-Function"> </a></h2><p>The YOLO loss function is the second most important aspect of the algorithm. The basic concept behind all these losses is that are the sum squared error, and if we look at the first part of the loss function is going to be the loss for the box coordinate for the midpoint (taking the $x$ midpoint value and subtractining from the predicted $\hat{x}$ squared). The $\mathbb{1}_{ij}^{obj}$ is the identity function which is calculated when there is an object in the cell, so summurizing there is:</p>
<ul>
<li>$\mathbb{1}_{i}^{obj}$ is 1 when there is an object in the cell $i$ otherwise is 0.</li>
<li>$\mathbb{1}_{ij}^{obj}$ is the $j^{th}$ bounding box prediction for the cell $i$ </li>
<li>$\mathbb{1}_{ij}^{noobj}$ has the same concept with the previous one, except that is 1 when there is no object and 0 when there is an object. </li>
</ul>
<p>So, to know which bounding box is responsible for outputing that bounding box is by looking at the cell and see which of the predicted bounding boxes has the highest Intersection over Union (IoU) value with the target bouning box. The one with the highest IoU will be the responsible bounding box for the prediction and will be send to the loss function.</p>
\begin{align}
&amp;\lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}[(x_i-\hat{x}_i)^2 + (y_i-\hat{y}_i)^2 ] \\&amp;+ \lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w}_i})^2 +(\sqrt{h_i}-\sqrt{\hat{h}_i})^2 ]\\
&amp;+ \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}(C_i - \hat{C}_i)^2 + \lambda_{noobj}\sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{noobj}(C_i - \hat{C}_i)^2 \\
&amp;+ \sum_{i=0}^{S^2} \mathbb{1}_{i}^{obj}\sum_{c \in classes}(p_i(c) - \hat{p}_i(c))^2 \\
\end{align}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Algorithm-Implementation">Algorithm Implementation<a class="anchor-link" href="#Algorithm-Implementation"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Change to yolo dir: /media/ioannis/DATA/Documents/Machine_learning/Project/src/yolo_v1
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="YOLO-model-architecure">YOLO model architecure<a class="anchor-link" href="#YOLO-model-architecure"> </a></h3><h4 id="Architecture-configuration-based-on-YOLO-paper">Architecture configuration based on YOLO paper<a class="anchor-link" href="#Architecture-configuration-based-on-YOLO-paper"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CNNBlock" class="doc_header"><code>class</code> <code>CNNBlock</code><a href="https://github.com/ioannispol/proejct_demo/tree/master/proejct_demo/yolov1.py#L70" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CNNBlock</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>This CNN block is used to as a blueprint of the conv layers for the YoloV1 model.
Need to use convolutional layers multiple times, so we'll use the CNNBlock for easy of use.</p>
<p>Args:
    nn ([type]): [description]</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="YoloV1" class="doc_header"><code>class</code> <code>YoloV1</code><a href="https://github.com/ioannispol/proejct_demo/tree/master/proejct_demo/yolov1.py#L88" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>YoloV1</code>(<strong><code>in_channels</code></strong>=<em><code>3</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">S</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A function to test YoloV1 model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">YoloV1</span><span class="p">(</span><span class="n">split_size</span><span class="o">=</span><span class="n">S</span><span class="p">,</span> <span class="n">num_boxes</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">C</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">448</span><span class="p">,</span> <span class="mi">448</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">test</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([2, 735])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

